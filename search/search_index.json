{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting Started with Regolo.ai","text":"<p>Tip</p> <p>For API's endpoints documentation visit docs.api.regolo.ai.</p>"},{"location":"#create-an-account","title":"Create an Account","text":"<p>To get started with Regolo.ai, sign up for an account at dashboard.regolo.ai.</p>"},{"location":"#generate-an-api-key","title":"Generate an API Key","text":"<p>Once logged in, navigate to the Virtual Keys section and create a new key. You can choose a specific model or select \"All models\" to use the key across all available models.</p>"},{"location":"#choose-your-client","title":"Choose your client","text":"<p>Regolo.ai is fully compatible with the OpenAI API, so you can use either:</p> <p>Regolo Python Library or OpenAI Python Library</p>"},{"location":"#chat-example","title":"Chat Example","text":"<p>Below is an example of how to create a simple chat application in python using regolo client.</p> Using Regolo Client <pre><code>    import streamlit as st\n    import regolo\n\n    regolo.default_key = \"YOUR-API-KEY-HERE\"\n    regolo.default_model = \"Llama-3.3-70B-Instruct\"\n\n    client = regolo.RegoloClient()\n\n    st.title(\"Regolo.ai Chat\")\n\n    if \"messages\" not in st.session_state:\n        st.session_state.messages = []\n\n    for msg in st.session_state.messages:\n        with st.chat_message(msg[\"role\"]):\n            st.markdown(msg[\"content\"])\n\n    user_input = st.chat_input(\"Write a message...\")\n    if user_input:\n        st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n\n        with st.chat_message(\"user\"):\n            st.markdown(user_input)\n\n        client.add_prompt_to_chat(role=\"user\", prompt=user_input)\n        for msg in st.session_state.messages:\n            client.add_prompt_to_chat(role=msg[\"role\"], prompt=msg[\"content\"])\n\n        response = client.run_chat()\n\n        role, content = response\n\n        st.session_state.messages.append({\"role\": role, \"content\": content})\n\n        with st.chat_message(role):\n            st.markdown(content)\n</code></pre>"},{"location":"completions/","title":"Completions and Chat","text":""},{"location":"completions/#static-completions","title":"Static Completions","text":"<p>Static completions allow you to generate text responses based on a given prompt using the Regolo API.</p> Using Regolo ClientPythonCURL <pre><code>import regolo\n\nregolo.default_key = \"&lt;YOUR_REGOLO_KEY&gt;\"\nregolo.default_model = \"Llama-3.3-70B-Instruct\"\n\nprint(regolo.static_completions(prompt=\"Tell me something about Rome.\"))\n</code></pre> <pre><code>import requests\n\napi_url = \"https://api.regolo.ai/v1/completions\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer YOUR_REGOLO_KEY\"\n}\ndata = {\n    \"model\": \"Llama-3.3-70B-Instruct\",\n    \"prompt\": \"Tell me something about Rome.\",\n    \"temperature\": 0.7\n}\n\nresponse = requests.post(api_url, headers=headers, json=data)\nprint(response.json())\n</code></pre> <pre><code>curl -X POST https://api.regolo.ai/v1/completions \n-H \"Content-Type: application/json\" \n-H \"Authorization: Bearer YOUR_REGOLO_KEY\" \n-d '{\n    \"model\": \"Llama-3.3-70B-Instruct\",\n    \"prompt\": \"Tell me something about Rome.\",\n    \"temperature\": 0.7\n}'\n</code></pre>"},{"location":"completions/#static-chat-completions","title":"Static Chat Completions","text":"<p>Static chat completions enable a more interactive session by providing conversation-like exchanges, you can send a series of messages. Each message has a role, such as <code>user</code>, <code>assistant</code> or <code>system</code>. The model processes these to continue the conversation naturally. This is useful for applications requiring a back-and-forth dialogue.</p> Using Regolo ClientPythonCURL <pre><code>import regolo\n\nregolo.default_key = \"&lt;YOUR_REGOLO_KEY&gt;\"\nregolo.default_model = \"Llama-3.3-70B-Instruct\"\n\nprint(regolo.static_chat_completions(messages=[{\"role\": \"user\", \"content\": \"Tell me something about rome\"}]))\n</code></pre> <pre><code>import requests\n\napi_url = \"https://api.regolo.ai/v1/chat/completions\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer YOUR_REGOLO_KEY\"\n}\ndata = {\n    \"model\": \"Llama-3.3-70B-Instruct\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Tell me something about Rome.\"}\n    ]\n}\n\nresponse = requests.post(api_url, headers=headers, json=data)\nprint(response.json())\n</code></pre> <pre><code>curl -X POST https://api.regolo.ai/v1/chat/completions \n-H \"Content-Type: application/json\" \n-H \"Authorization: Bearer YOUR_REGOLO_KEY\" \n-d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Tell me something about Rome.\"\n        }\n    ]\n}'\n</code></pre>"},{"location":"completions/#stream-chat-completions","title":"Stream Chat Completions","text":"<p>Stream chat completions provide real-time, incremental responses from the model, enabling dynamic interactions and reducing latency. This feature is beneficial for applications that require immediate feedback and continuous conversation flow.</p> <p>The streaming response is structured as JSON objects sent line by line. Each line typically contains metadata, including fields like <code>id</code>, <code>created</code>, <code>model</code>, and <code>object</code>, along with the <code>choices</code> array. Within <code>choices</code>, there is a <code>delta</code> object, which holds the <code>content</code> field representing the actual text response from the model. This structure allows applications to parse and process the conversational content as it arrives, ensuring efficient and timely updates to the user interface.</p> Using Regolo ClientPython <pre><code>import regolo\n\nregolo.default_key = \"&lt;YOUR_REGOLO_KEY&gt;\"\nregolo.default_model = \"Llama-3.3-70B-Instruct\"\n\nclient = regolo.RegoloClient()\nresponse = client.run_chat(user_prompt=\"Tell me something about Rome.\", full_output=True, stream=True)\n\n\nwhile True:\n    try:\n        print(next(response))\n    except StopIteration:\n        break\n</code></pre> <pre><code>import requests\n\napi_url = \"https://api.regolo.ai/v1/chat/completions\"\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer YOUR_REGOLO_KEY\"\n}\ndata = {\n    \"model\": \"Llama-3.3-70B-Instruct\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Tell me something about Rome.\"}\n    ],\n    \"stream\": True\n}\n\nresponse = requests.post(api_url, headers=headers, json=data, stream=True)\n\nfor line in response.iter_lines():\n    if line:\n        print(line.decode('utf-8'))\n</code></pre> <p>For the exhaustive API's endpoints documentation visit docs.api.regolo.ai.</p>"},{"location":"embedding/","title":"Embedding","text":"<p>The embedding API allows you to get a vector representation of the input to be used from machine learning models or algorithms, leveraging models like <code>gte-Qwen2</code>.</p>"},{"location":"embedding/#api-call-parameters","title":"API Call Parameters","text":"<ul> <li><code>input</code>: A string describing the sentence, such as \"A white cat resting in Rome.\"</li> <li><code>model</code>: The identifier for the model used in image generation, e.g., \"gte-Qwen2.\"</li> </ul> Using Regolo ClientPythonCURL <pre><code>import regolo\n\nregolo.default_key = \"&lt;YOUR_REGOLO_KEY&gt;\"\nregolo.default_embedder_model = \"gte-Qwen2\"\n\n\nembeddings = regolo.static_embeddings(input_text=[\"A white cat resting in Rome\", \"A white cat resting in Paris\"])\n\nprint(embeddings)\n</code></pre> <pre><code>import requests\nimport json\n\nurl = 'https://api.regolo.ai/v1/embeddings'\nheaders = {\n    'Authorization': 'Bearer YOUR_REGOLO_KEY',\n    'Content-Type': 'application/json'\n}\n\ndata = {\n    \"prompt\": \"A white cat resting in Rome\",\n    \"model\": \"gte-Qwen2\",\n}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\n\nif response.status_code == 200:\n    with open(\"./embedding.json\", 'w') as _file:\n        json.dump(response.json(), _file)\nelse:\n    print(\"Failed embedding request:\", response.status_code, response.text)\n</code></pre> <pre><code>curl -X POST https://api.regolo.ai/v1/embeddings\n-H \"Content-Type: application/json\"\n-H \"Authorization: Bearer YOUR_REGOLO_KEY\"\n-d '{\n    \"model\": \"gte-Qwen2\",\n    \"input\": \"The quick brown fox jumps over the lazy dog\"\n}'\n</code></pre> <p>For the exhaustive API's endpoints documentation visit docs.api.regolo.ai.</p>"},{"location":"images/","title":"Images Generation","text":"<p>The image generation API allows you to create images based on textual descriptions, leveraging models like <code>FLUX.1-dev</code>.</p>"},{"location":"images/#api-call-parameters","title":"API Call Parameters","text":"<ul> <li><code>prompt</code>: A string describing the desired image, such as \"A white cat resting in Rome.\"</li> <li><code>n</code>: An integer specifying the number of images to generate. Generating more images increases response time, so it's best to keep this number small for faster performance.</li> <li><code>model</code>: The identifier for the model used in image generation, e.g., \"FLUX.1-dev.\"</li> <li><code>size</code>: A string defining the dimensions of the images. Supported sizes are \"256x256,\" \"512x512,\" and \"1024x1024.\"</li> </ul> <p>Larger images take longer to generate, so consider using smaller sizes for quicker results.</p> <p>Tip</p> <p>If you require larger images, consider using an image upscaler after generation. This can help achieve the desired resolution without increasing the generation time</p> Using Regolo ClientPythonCURL <pre><code>import regolo\nfrom io import BytesIO\nfrom PIL import Image\n\nregolo.default_image_model = \"FLUX.1-dev\"\nregolo.default_key = \"&lt;YOUR_REGOLO_KEY&gt;\"\n\nimg_bytes = regolo.static_image_create(prompt=\"A white cat resting in Rome\")[0]\n\nimage = Image.open(BytesIO(img_bytes))\n\nimage.show()\n</code></pre> <pre><code>import requests\nimport json\nfrom PIL import Image\nimport io\nimport base64\n\nurl = 'https://api.regolo.ai/v1/images/generations'\nheaders = {\n    'Authorization': 'Bearer YOUR_REGOLO_KEY',\n    'Content-Type': 'application/json'\n}\n\ndata = {\n    \"prompt\": \"A white cat resting in Rome\",\n    \"n\": 2,\n    \"model\": \"FLUX.1-dev\",\n    \"size\": \"1024x1024\"\n}\n\nresponse = requests.post(url, headers=headers, data=json.dumps(data))\n\nif response.status_code == 200:\n    response_data = response.json()\n\n    for index, item in enumerate(response_data['data']):\n        b64_image = item['b64_json']\n        image_data = base64.b64decode(b64_image)\n\n        image_stream = io.BytesIO(image_data)\n        image = Image.open(image_stream)\n\n        image.show(title=f'Generated Image {index + 1}')\nelse:\n    print(\"Failed to generate images:\", response.status_code, response.text)\n</code></pre> <pre><code>curl --request POST \\\n  --url 'https://api.regolo.ai/v1/images/generations?=' \\\n  --header 'Authorization: Bearer YOUR_REGOLO_KEY' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"prompt\": \"A white cat resting in Rome\",\n    \"n\": 2,\n    \"model\": \"FLUX.1-dev\",\n    \"size\": \"1024x1024\"\n}'\n</code></pre> <p>For the exhaustive API's endpoints documentation visit docs.api.regolo.ai.</p>"},{"location":"stt/","title":"Speech To Text","text":"<p>The Speech to Text (STT) API enables you to extract and transcribe text from audio files using models such as <code>faster-whisper-large-v3</code>. We recommend using audio chunks of less than 2 minutes to prevent hallucinations and duplicate transcriptions.</p>"},{"location":"stt/#api-call-parameters","title":"API Call Parameters","text":"<ul> <li><code>file</code>: A binary audio file in OGG format.</li> <li><code>model</code>: The identifier for the model used for transcription, e.g., <code>faster-whisper-large-v3</code>.</li> <li><code>language</code>: A string specifying the language of the audio, such as <code>english</code>, <code>italian</code>, etc.</li> </ul>"},{"location":"stt/#important-note","title":"Important Note","text":"<p>The models have a timeout limit. It is recommended to split audio files into smaller segments, such as five-minute clips, to ensure optimal performance.</p>"},{"location":"stt/#example-curl-request","title":"Example CURL Request","text":"CURL <pre><code>curl --request POST \\\n  --url 'https://api.regolo.ai/v1/audio/transcriptions' \\\n  --header 'Authorization: Bearer YOUR_REGOLO_KEY' \\\n  --header \"Content-Type: multipart/form-data\"  \n  --data '{\n    \"file\": @\"/path/of/your/file\",\n    \"model\": \"faster-whisper-large-v3\"\n}\n</code></pre>"},{"location":"stt/#example-implementation","title":"Example Implementation","text":"<p>For a practical example of how to use this API, you can refer to the Telegram Transcriber GitHub Repository. This repository provides a complete implementation for transcribing audio messages from Telegram using the Speech to Text API.</p> <p>For the exhaustive API's endpoints documentation visit docs.api.regolo.ai.</p>"},{"location":"vision/","title":"Vision models","text":"<p>Vision completions enable the processing of images alongside text, allowing for a wide range of applications such as image description, object recognition, and data extraction from visual content. By sending a combination of text prompts and image URLs, the model can provide insightful responses based on the visual input.</p>"},{"location":"vision/#vision-completions","title":"Vision Completions","text":"<p>You can provide images in two ways:</p> <ul> <li>Remote URL: Supply a publicly accessible URL pointing to the image.</li> <li>Base64 Encoding: Encode the image in base64 format and pass it in the <code>image_url</code> field.</li> </ul>"},{"location":"vision/#remote-image-url","title":"Remote Image URL","text":"Using Regolo ClientPythonCURL <pre><code>import regolo\n\nregolo.default_key = \"YOUR_REGOLO_KEY\"\nregolo.default_model = \"Qwen2.5-VL-32B-Instruct\"\n\nprint(regolo.static_chat_completions(messages=[{\n    \"role\": \"user\",\n    \"content\": [\n        {\n            \"type\": \"text\",\n            \"text\": \"What\u2019s in this image?\"\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/960px-Colosseo_2020.jpg\"},\n            \"format\": \"image/jpeg\"\n        }\n    ]\n}]))\n</code></pre> <pre><code>import requests\n\nurl = \"https://api.regolo.ai/v1/chat/completions\"\npayload = {\n    \"model\": \"Qwen2.5-VL-32B-Instruct\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"What\u2019s in this image?\"\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/960px-Colosseo_2020.jpg\"},\n                    \"format\": \"image/jpeg\"\n                }\n            ]\n        }\n    ]\n}\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer YOUR_REGOLO_KEY\"\n}\n\nresponse = requests.post(url, json=payload, headers=headers)\nprint(response.json())\n</code></pre> <pre><code>curl -X POST https://api.regolo.ai/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer YOUR_REGOLO_KEY\" \\\n-d '{\n    \"model\": \"Qwen2.5-VL-32B-Instruct\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"What\u2019s in this image?\"\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Colosseo_2020.jpg/960px-Colosseo_2020.jpg\"},\n                    \"format\": \"image/jpeg\"\n                }\n            ]\n        }\n    ]\n}'\n</code></pre>"},{"location":"vision/#base64-encoding","title":"Base64 Encoding","text":"<p>This script demonstrates how to encode a local image as Base64 and send it to a multimodal model (text + image) for analysis.</p> <p>Replace 'YOUR-API-KEY' with your actual API key before running.</p> Python <pre><code>import base64\nimport json\nimport requests\nfrom pathlib import Path\n\nAPI_URL = \"https://api.regolo.ai/v1/chat/completions\"\nAPI_KEY = \"YOUR-API-KEY\"\nMODEL = \"gemma-3-27b-it\"\n\nIMAGE_PATH = Path(\"colosseo.jpg\")\n\nif not IMAGE_PATH.exists():\n    raise FileNotFoundError(f\"Image not found: {IMAGE_PATH.resolve()}\")\n\nwith open(IMAGE_PATH, \"rb\") as f:\n    image_bytes = f.read()\n\nimage_b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n\npayload = {\n    \"model\": MODEL,\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"What\u2019s in this image?\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{image_b64}\",\n                        \"format\": \"image/jpeg\"\n                    }\n                }\n            ]\n        }\n    ]\n}\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {API_KEY}\"\n}\n\nprint(\"Sending request to Regolo AI API...\")\nresponse = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n\nif response.status_code != 200:\n    print(f\"Error {response.status_code}:\")\n    print(response.text)\nelse:\n    result = response.json()\n    try:\n        content = result[\"choices\"][0][\"message\"][\"content\"]\n        print(\"Model response:\")\n        print(content)\n    except Exception:\n        print(\"Unexpected response format:\")\n        print(response.text)\n</code></pre>"}]}