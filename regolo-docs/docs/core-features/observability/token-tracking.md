# Token Usage Tracking

Track and monitor token consumption across your API calls.

## Token Types

### Input Tokens

Tokens in your prompt:

```python
messages = [{"role": "user", "content": "Summarize this document..."}]
# Input tokens: ~10 tokens

response = regolo.static_chat_completions(messages=messages)
print(f"Input tokens: {response.usage.prompt_tokens}")
```

### Output Tokens

Tokens generated by the model:

```python
response = regolo.static_chat_completions(
    messages=messages,
    max_tokens=100
)
print(f"Output tokens: {response.usage.completion_tokens}")
```

### Total Tokens

Sum of input and output:

```python
response = regolo.static_chat_completions(messages=messages)
print(f"Total tokens: {response.usage.total_tokens}")
# = input_tokens + output_tokens
```

## Token Tracking Dashboard

Access token metrics at [dashboard.regolo.ai/tokens](https://dashboard.regolo.ai/tokens)

### Daily Token Usage

```
Day 1: 500K tokens
Day 2: 650K tokens
Day 3: 800K tokens
...
Month Total: 15M tokens
```

### Tokens by Model

```
Llama-3.3-70B: 8M tokens (53%)
Llama-2-7B:    5M tokens (33%)
Embedding:     2M tokens (14%)
```

### Tokens by User

Track per-user consumption:

```
user_123: 5M tokens
user_456: 3M tokens
user_789: 2M tokens
```

## Token Estimation

### Estimation Guide

General rules of thumb:

```
1 English word    ≈ 1.3 tokens
1 token          ≈ 4 characters
1 sentence       ≈ 8 tokens
1 paragraph      ≈ 40 tokens
1 page of text   ≈ 500 tokens
```

### Estimation in Code

```python
import regolo

# Estimate before making request
tokens_estimate = regolo.estimate_tokens(
    messages=[{"role": "user", "content": "Your prompt here"}]
)

print(f"Estimated tokens: {tokens_estimate}")
print(f"Estimated cost: ${tokens_estimate * 0.00001:.4f}")
```

## Token Limits

### Model-Specific Limits

| Model | Context | Max Output |
|-------|---------|------------|
| Llama-3.3-70B | 8K | 4K |
| Llama-2-7B | 4K | 2K |
| Embedding | 8K | N/A |

### Account Limits

Daily token quotas:

```
Free: 100K tokens/day
Pro: 1M tokens/day
Enterprise: Custom
```

## Token Optimization

### 1. Reduce Input Tokens

```python
# Before: 500 token prompt
prompt = """
You are a helpful assistant. Please follow these guidelines:
1. Be concise
2. Be accurate
...
(many more guidelines)
"""

# After: 50 token optimized prompt
prompt = "Helpful AI assistant. Concise & accurate answers."

# Savings: 90%
```

### 2. Limit Output Length

```python
# Before: No limit (may generate 500+ tokens)
response = regolo.static_chat_completions(
    messages=messages
)

# After: Limit to necessary tokens
response = regolo.static_chat_completions(
    messages=messages,
    max_tokens=100  # Limit output
)
```

### 3. Use Efficient Models

```python
# Expensive: 70B parameter model
model = "Llama-3.3-70B"  # 150ms, more tokens

# Efficient: 7B parameter model
model = "Llama-2-7B"  # 80ms, fewer tokens
```

### 4. Cache Common Requests

```python
# Repeated question (no caching)
for _ in range(100):
    response = regolo.static_chat_completions(
        messages=[{"role": "user", "content": "What is AI?"}]
    )
# Cost: 100 × 50 tokens = 5,000 tokens

# With caching
response = regolo.static_chat_completions(
    messages=[{"role": "user", "content": "What is AI?"}],
    cache_ttl=3600
)
# Cost: 1 × 50 tokens = 50 tokens (99% savings)
```

## Token Analytics API

### Get Token Usage

```python
import regolo

# Get daily token usage
usage = regolo.get_token_usage(
    start_date="2024-12-01",
    end_date="2024-12-18",
    group_by="day"
)

for day_usage in usage:
    print(f"{day_usage.date}: {day_usage.tokens} tokens")
```

### Get Model-Specific Usage

```python
# Token usage by model
usage_by_model = regolo.get_token_usage(
    start_date="2024-12-01",
    end_date="2024-12-18",
    group_by="model"
)

for model_usage in usage_by_model:
    print(f"{model_usage.model}: {model_usage.tokens} tokens")
```

### Export Token Data

```python
# Export to CSV
csv_data = regolo.export_token_usage(
    start_date="2024-12-01",
    end_date="2024-12-18",
    format="csv"
)
```